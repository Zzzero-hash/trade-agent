# Unified Trading RL Agent Configuration
# This configuration consolidates all settings for data, model, backtest, and live trading

# Environment and system settings
environment: production # development, staging, production
debug: false
log_level: INFO

# ============================================================================
# DATA CONFIGURATION
# ============================================================================
data:
  # Data sources and API configuration
  sources:
    primary: yfinance # yfinance, alpaca, alphavantage, ccxt
    backup: yfinance
    real_time_enabled: false
    update_frequency: 60 # seconds

  # Data collection settings
  symbols:
    - AAPL
    - GOOGL
    - MSFT
    - TSLA
    - AMZN
    - EURUSD=X
    - GBPUSD=X
    - USDJPY=X

  # Date ranges
  start_date: "2023-01-01"
  end_date: "2024-01-01"
  timeframe: "1d" # 1d, 1h, 5m, 1m

  # Dataset composition
  real_data_ratio: 0.95 # 95% real data for production
  min_samples_per_symbol: 2500
  sequence_length: 60
  prediction_horizon: 1
  overlap_ratio: 0.8

  # Feature engineering
  technical_indicators: true
  sentiment_features: true
  market_regime_features: true
  alternative_data: false

  # Data quality settings
  outlier_threshold: 5.0
  missing_value_threshold: 0.25

  # Cache and storage
  cache_dir: "data/cache"
  cache_ttl_hours: 24
  data_path: "data/"
  output_dir: "data/processed" # Changed from "outputs/datasets"

  # Performance settings
  max_workers: 4
  chunk_size: 1000
  use_memory_mapping: true

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
model:
  # Model type and algorithm
  type: cnn_lstm # cnn_lstm, rl, hybrid
  algorithm: sac # ppo, sac, td3 (for RL models)

  # CNN+LSTM architecture
  cnn_filters: [64, 128, 256]
  cnn_kernel_sizes: [3, 3, 3]
  cnn_dropout: 0.2
  lstm_units: 128
  lstm_layers: 2
  lstm_dropout: 0.2
  dense_units: [64, 32]
  output_dim: 1
  activation: "relu"
  use_attention: false

  # Training parameters
  batch_size: 32
  learning_rate: 0.001
  weight_decay: 1e-5
  optimizer: "adam" # adam, sgd, rmsprop
  epochs: 100
  early_stopping_patience: 10
  reduce_lr_patience: 5
  reduce_lr_factor: 0.5

  # RL-specific settings
  total_timesteps: 1000000
  eval_frequency: 10000
  save_frequency: 50000

  # Loss and metrics
  loss_function: "mse" # mse, mae, huber
  metrics:
    - "mae"
    - "rmse"
    - "correlation"
    - "r2_score"

  # Model persistence
  model_save_path: "models/"
  checkpoint_dir: "models/checkpoints"
  save_best_only: true
  save_frequency_epochs: 5

  # Device and performance
  device: "auto" # auto, cpu, cuda
  num_workers: 4
  mixed_precision: true
  gradient_checkpointing: false

# ============================================================================
# BACKTEST CONFIGURATION
# ============================================================================
backtest:
  # Test period
  start_date: "2024-01-01"
  end_date: "2024-12-31"

  # Instruments to test
  symbols:
    - AAPL
    - GOOGL
    - MSFT

  # Capital and position sizing
  initial_capital: 100000.0
  commission_rate: 0.001 # 0.1%
  slippage_rate: 0.0001 # 0.01%

  # Risk management
  max_position_size: 0.1 # 10% of portfolio
  max_leverage: 1.0
  stop_loss_pct: 0.02 # 2%
  take_profit_pct: 0.05 # 5%

  # Evaluation metrics
  metrics:
    - "total_return"
    - "sharpe_ratio"
    - "max_drawdown"
    - "win_rate"
    - "profit_factor"
    - "calmar_ratio"
    - "sortino_ratio"

  # Output settings
  output_dir: "backtest_results"
  save_trades: true
  save_portfolio: true
  generate_plots: true
  plot_dir: "plots/backtest"

# ============================================================================
# LIVE TRADING CONFIGURATION
# ============================================================================
live:
  # Exchange and broker settings
  exchange: alpaca # alpaca, ib, paper, ccxt
  paper_trading: true

  # API configuration (load from environment variables)
  # api_key: ${ALPACA_API_KEY}
  # secret_key: ${ALPACA_SECRET_KEY}
  # base_url: ${ALPACA_BASE_URL}

  # Trading symbols
  symbols:
    - AAPL
    - GOOGL
    - MSFT

  # Execution settings
  order_timeout: 60 # seconds
  max_slippage: 0.001 # 0.1%
  commission_rate: 0.001 # 0.1%
  execution_frequency: 5 # seconds
  market_hours_only: true

  # Risk management
  max_position_size: 0.1 # 10% of portfolio
  max_leverage: 1.0
  max_drawdown: 0.15 # 15%
  stop_loss_pct: 0.02 # 2%
  take_profit_pct: 0.05 # 5%

  # VaR and risk metrics
  var_confidence_level: 0.05 # 95% VaR
  var_time_horizon: 1
  kelly_fraction: 0.25
  risk_per_trade: 0.02 # 2% risk per trade

  # Portfolio settings
  initial_capital: 100000.0
  rebalance_frequency: 3600 # seconds
  max_positions: 10

  # Monitoring and alerts
  monitoring_interval: 60 # seconds
  alerts_enabled: true
  email_alerts: false
  slack_alerts: false

# ============================================================================
# MONITORING AND LOGGING
# ============================================================================
monitoring:
  # Logging configuration
  log_level: "INFO"
  log_file: "logs/trading_system.log"
  structured_logging: true

  # Experiment tracking
  experiment_name: "trading_rl_agent"
  tracking_uri: "sqlite:///mlruns.db" # MLflow tracking URI
  mlflow_enabled: true
  tensorboard_enabled: true
  tensorboard_log_dir: "logs/tensorboard"

  # Performance tracking
  metrics_enabled: true
  metrics_frequency: 300 # seconds
  health_check_interval: 30 # seconds

  # Alerting
  alerts_enabled: true
  email_alerts: false
  slack_alerts: false

# ============================================================================
# INFRASTRUCTURE CONFIGURATION
# ============================================================================
infrastructure:
  # Distributed computing
  distributed: false
  ray_address: null # Ray cluster address
  num_workers: 4
  gpu_enabled: true

  # Storage
  model_registry_path: "models"
  experiment_tracking: "mlflow" # mlflow, wandb, tensorboard

  # Monitoring
  enable_monitoring: true
  metrics_port: 8080
  health_check_interval: 30

  # System resources
  use_gpu: false
  max_workers: 4
  memory_limit: "8GB"

# ============================================================================
# HYPERPARAMETER OPTIMIZATION
# ============================================================================
hyperopt:
  enabled: false
  n_trials: 50
  timeout: 3600 # seconds

  # Search space
  search_space:
    learning_rate:
      type: "log_uniform"
      low: 1e-5
      high: 1e-2
    batch_size:
      type: "categorical"
      choices: [16, 32, 64, 128]
    lstm_units:
      type: "categorical"
      choices: [64, 128, 256]
    cnn_filters:
      type: "categorical"
      choices: [[32, 64], [64, 128], [64, 128, 256]]

# ============================================================================
# PRODUCTION CONFIGURATION
# ============================================================================
production:
  # Model serving
  model_format: "torchscript" # torchscript, onnx
  model_version: "v1.0.0"

  # API configuration
  api_host: "0.0.0.0"
  api_port: 8000
  api_workers: 4

  # Monitoring
  health_check_interval: 30 # seconds
  metrics_export_interval: 60 # seconds
