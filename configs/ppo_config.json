{
  "ppo": {
    "algorithm": "PPO",
    "learning_rate": 3e-4,
    "n_steps": 2048,
    "batch_size": 64,
    "n_epochs": 10,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "ent_coef": 0.0,
    "vf_coef": 0.5,
    "max_grad_norm": 0.5,
    "seed": 42
  },
  "mlp_features": {
    "input_dim": 514,
    "hidden_layers": [256, 128, 64],
    "output_dim": 64,
    "activation": "ReLU"
  },
  "training": {
    "total_timesteps": 1000000,
    "eval_freq": 10000,
    "checkpoint_freq": 50000
  }
}
