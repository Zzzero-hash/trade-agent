# Trading RL Agent

[![Coverage Status](https://codecov.io/gh/Zzzero-hash/trading-rl-agent/branch/main/graph/badge.svg)](https://codecov.io/gh/Zzzero-hash/trading-rl-agent)

A research-focused system combining CNN+LSTM market intelligence with reinforcement learning (RL) optimization.
_Current status: core functionality validated, environment testing framework complete, and all tests passing._

---

## üöÄ Quick Start

1. **Clone the repo**

   ```bash
   git clone https://github.com/Zzzero-hash/trading-rl-agent.git
   cd trading-rl-agent
   ```

2. **Install dependencies**

   ```bash
   pip install -r requirements-finrl.txt
   pip install finrl[full] "ray[rllib]"
   ```

3. **Run tests**
   ```bash
   pytest
   ```
   All ~733 tests should pass, validating the core environment and integration.

---

## üì¶ Project Structure

```
trading-rl-agent/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agents/           # RL agents (SAC, PPO, EnsembleAgent(RLlib))
‚îÇ   ‚îú‚îÄ‚îÄ models/           # CNN+LSTM architectures
‚îÇ   ‚îú‚îÄ‚îÄ data/             # Data processing & feature generation
‚îÇ   ‚îú‚îÄ‚îÄ envs/             # Trading environments
‚îÇ   ‚îî‚îÄ‚îÄ deployment/       # Serving configurations
‚îú‚îÄ‚îÄ tests/                # Unit and integration tests
‚îú‚îÄ‚îÄ cnn_lstm_hparam_clean.ipynb  # Hyperparameter tuning notebook
‚îú‚îÄ‚îÄ build_production_dataset.py  # Dataset generation script
‚îî‚îÄ‚îÄ data/                 # Sample datasets
```

---

## üß† Core Components

- **CNN+LSTM Market Intelligence**
  - Sequence input of market features + technical indicators
  - Convolutional layers ‚Üí LSTM with attention ‚Üí trend forecasts

- **RL Decision Engine**
  - Built on FinRL + Ray RLlib + Stable Baselines3[contrib]
  - Supports SAC, PPO
  - Risk-adjusted reward functions integrated

- **Testing Framework**
  - Fully automated environment tests
  - Backtesting simulation with transaction costs
  - Coverage across data pipelines, models, and agents

---

## ‚öôÔ∏è Usage Examples

### Train an SAC Agent

```python
from finrl.env.env_stocktrading import StockTradingEnv
from ray.rllib.algorithms.sac import SACConfig
from ray import tune

config = SACConfig().environment(StockTradingEnv)
tune.Tuner("SAC", param_space=config, stop={"training_iteration": 10}).fit()
```

### Backtest with Sample Data

```bash
python build_production_dataset.py --symbols AAPL,MSFT --start 2024-01-01
python src/train_finrl_agent.py --agent sac --data sample --backtesting realistic
```

---

## üîç Current Status

- ‚úÖ Environment testing framework complete
- ‚úÖ Core CNN+LSTM & RL integration validated
- ‚úÖ Sample datasets included
- ‚úÖ ~733 tests passing

> **Note:** This project is research-oriented. Sample data and workflows are provided for experimentation. Production deployment, professional data feeds, advanced risk modules, and multi-asset portfolio features remain under active development.

---

## ü§ù Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for:

- Development setup
- Code standards
- Pull request guidelines

---

## üìÑ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

> **Disclaimer:** For educational and research purposes only. Not financial advice. Always paper‚Äêtrade and consult professionals before deploying strategies with real capital.
