{
  "name": "Existing Dockerfile",
  "build": {
    "context": "..",
    "dockerfile": "../Dockerfile"
  },
  "features": {
    "ghcr.io/devcontainers/features/nvidia-cuda:latest": {},
    "ghcr.io/devcontainers/features/git-lfs:1": {
      "autoPull": true,
      "version": "latest"
    },
    "ghcr.io/devcontainers/features/github-cli:1": {
      "installDirectlyFromGitHubRelease": true,
      "version": "latest"
    },
    "ghcr.io/devcontainers/features/python:1": {
      "installTools": true,
      "optimize": true,
      "version": "os-provided"
    }
  },
  "runArgs": ["--gpus=all"],
  "hostRequirements": {
    "gpu": "optional"
  },
  "postCreateCommand": "chmod -R 755 /workspace && find /workspace -name '*.sh' -exec chmod +x {} \\; && pip install -e . && python -c 'import torch; print(f\"CUDA available: {torch.cuda.is_available()}\")'"
}
