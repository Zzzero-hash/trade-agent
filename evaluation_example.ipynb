{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c227455c",
   "metadata": {},
   "source": [
    "# Evaluating a Trained RL Agent\n",
    "\n",
    "This notebook demonstrates how to run `evaluate_agent.py` on a sample dataset and view the resulting metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate_agent.py --data data/sample_data.csv \\\n",
    "    --checkpoint checkpoints/agent.pth --agent sac --output results/evaluation.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2f20c",
   "metadata": {},
   "source": [
    "After running the script, the metrics file `results/evaluation.json` can be loaded and displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"results/evaluation.json\") as f:\n",
    "    metrics = json.load(f)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
