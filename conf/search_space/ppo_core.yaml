# Optuna search space for PPO agent
# Usage: python scripts/train_sl_hydra.py -m hydra/sweeper=optuna \
#          model=ppo +search_space=ppo_core optuna.n_trials=30

hydra:
  sweeper:
    search_space:
      model.learning_rate:
        type: float
        low: 1e-5
        high: 1e-3
        log: true
      model.n_steps:
        type: categorical
        choices: [512, 1024, 2048]
      model.batch_size:
        type: categorical
        choices: [32, 64, 128]
      model.gamma:
        type: float
        low: 0.90
        high: 0.9999
      model.clip_range:
        type: float
        low: 0.1
        high: 0.4
      model.ent_coef:
        type: float
        low: 0.0
        high: 0.1
      random_state:
        type: int
        low: 1
        high: 10000
